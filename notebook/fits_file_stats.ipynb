{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from scipy.io import loadmat\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_data_index(fits_file: str):\n",
    "    '''\n",
    "    Finds the location of a FITS file's data array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file to be searched.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The index of the data array in the FITS file.\n",
    "    '''\n",
    "\n",
    "    file_index = 0\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    info = file[file_index]\n",
    "    data = info.data\n",
    "    while data is None:\n",
    "        #going through the indices of file to find the array\n",
    "        try:\n",
    "            file_index += 1\n",
    "            info = file[file_index]\n",
    "            data = info.data\n",
    "        except:\n",
    "            print(f'Error in locating data index of {fits_file}')\n",
    "\n",
    "    return file_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_theta(coord, amp, sigma, theta, mu_x, mu_y):\n",
    "    x, y = coord\n",
    "    return amp * np.exp(-(((x-mu_x)*math.cos(theta)+(y-mu_y)*math.sin(theta))**2+(-(x-mu_x)*math.sin(theta)+(y-mu_y)*math.cos(theta))**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_stats(fits_file: str, center: list = [], radius: list = [], invert: bool = False, Gaussian: bool = True, internal: bool = True):\n",
    "    '''\n",
    "    Finds the statistics of a region of an image.\n",
    "\n",
    "    The region can be the union of circles or the complement of such a region.\n",
    "\n",
    "    The statistics are the region's maximum flux in Jy and its coordinates in pixels, the region's rms in Jy,\n",
    "    the coordinates in pixels of the image's center, the image's beam size in arcseconds squared,\n",
    "    the image's x- and y-axis lengths in arcseconds, and the area included in the mask in arcseconds squared.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    center : list (optional)\n",
    "        A list of center coordinates in units of pixels.\n",
    "        If no center coordinates are given, eventually defaults to ((length of x-axis)/2, (length of y-axis)/2), rounded up.\n",
    "    radius : list (optional)\n",
    "        A list of search radii in units of arcsec.\n",
    "        If no radius list is given, defaults to an empty list.\n",
    "    invert : bool (optional)\n",
    "        Whether to swap the inclusion and exclusion regions.\n",
    "        If no value is given, defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with:\n",
    "            float\n",
    "                The region's maximum flux in Jy.\n",
    "            tuple (int, int)\n",
    "                The coordinates in pixels of the region's maximum flux.\n",
    "            float\n",
    "                The region's rms in Jy.\n",
    "            tuple (int, int)\n",
    "                The coordinates in pixels of the image's center.\n",
    "            float\n",
    "                The image's beam size in arcseconds squared.\n",
    "            float\n",
    "                The image's x-axis length in arcsec.\n",
    "            float\n",
    "                The image's y-axis length in arcsec.\n",
    "            float\n",
    "                The area included in the mask in arcseconds squared.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    IndexError\n",
    "        If center list and radius list are of different lengths.\n",
    "    '''\n",
    "\n",
    "    if center != [] and len(center) != len(radius):\n",
    "        raise IndexError ('Center list and radius list are of different lengths')\n",
    "\n",
    "    i = fits_data_index(fits_file)\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    #extract data array\n",
    "    info = file[i]\n",
    "    data = info.data\n",
    "\n",
    "    #getting dimensions for array\n",
    "    try:\n",
    "        dims = data.shape\n",
    "        x_dim = dims[1]\n",
    "        y_dim = dims[2]\n",
    "    except:\n",
    "        print('Data dimension error')\n",
    "\n",
    "    x_dist_array = np.tile(np.arange(x_dim),(y_dim, 1)) #array of each pixel's horizontal distance (in pixels) from y-axis\n",
    "    y_dist_array = x_dist_array.T #array of each pixel's vertical distance (in pixels) from x-axis\n",
    "\n",
    "    #keep center pixel coordinates if specified, set to default if unspecified\n",
    "    center_pix = center\n",
    "    field_center = (round(x_dim/2), round(y_dim/2))\n",
    "    if center == []:\n",
    "        center_pix = [field_center]\n",
    "        if len(radius) > 1:\n",
    "            center_pix = center_pix * len(radius)\n",
    "\n",
    "    #find units of axes\n",
    "    x_unit = info.header['CUNIT1']\n",
    "    y_unit = info.header['CUNIT2']\n",
    "\n",
    "    #find cell size (units of arcsec)\n",
    "    x_cell_size = (Angle(info.header['CDELT1'], x_unit)).to(u.arcsec)\n",
    "    y_cell_size = (Angle(info.header['CDELT2'], y_unit)).to(u.arcsec)\n",
    "\n",
    "    #find major axis (units of arcsec), minor axis (units of arcsec), beam size (units of arcsec^2)\n",
    "    beam_size = ((np.pi/4) * info.header['BMAJ'] * info.header['BMIN'] * Angle(1, x_unit) * Angle(1, y_unit) / np.log(2)).to(u.arcsec**2)\n",
    "\n",
    "    #find axis sizes\n",
    "    x_axis_size = info.header['NAXIS1'] * x_cell_size\n",
    "    y_axis_size = info.header['NAXIS2'] * y_cell_size\n",
    "\n",
    "    #distance from center array\n",
    "    dist_from_center =((((x_dist_array - center_pix[0][0])*x_cell_size)**2 + ((y_dist_array - center_pix[0][1])*y_cell_size)**2)**0.5)\n",
    "\n",
    "    #boolean mask and apply\n",
    "    mask = (dist_from_center <= radius[0] * u.arcsec)\n",
    "    if len(center) > 1:\n",
    "        for j in range(1, len(center)):\n",
    "            dist_from_center = ((((x_dist_array - center_pix[j][0])*x_cell_size)**2 + ((y_dist_array - center_pix[j][1])*y_cell_size)**2)**0.5)\n",
    "            mask = np.logical_or(mask, (dist_from_center <= radius[j] * u.arcsec))\n",
    "\n",
    "    if invert:\n",
    "        mask = np.logical_not(mask)\n",
    "\n",
    "    incl_area = float(mask.sum() * x_cell_size * y_cell_size / (u.arcsec)**2)\n",
    "\n",
    "    masked_data = data[0][mask]\n",
    "\n",
    "    #get peak, rms, beam_size values\n",
    "    try:\n",
    "        peak = float(max(masked_data))\n",
    "    except ValueError:\n",
    "        print('No values after mask applied. Check inclusion and exclusion radii.')\n",
    "\n",
    "    #find coordinates of peak\n",
    "    peak_pix = np.where(data[0] == peak)\n",
    "    peak_x = peak_pix[1][0]\n",
    "    peak_y = peak_pix[0][0]\n",
    "    peak_coord = (peak_x, peak_y)\n",
    "\n",
    "    if Gaussian and internal and (peak_x - 2) >= 0 and (peak_x + 2) <= x_dim and (peak_y - 2) >= 0 and (peak_y + 2) <= y_dim:\n",
    "        neg2_2 = data[0][peak_x - 2][peak_y + 2]\n",
    "        neg2_1 = data[0][peak_x - 2][peak_y + 1]\n",
    "        neg2_0 = data[0][peak_x - 2][peak_y]\n",
    "        neg2_neg1 = data[0][peak_x - 2][peak_y - 1]\n",
    "        neg2_neg2 = data[0][peak_x - 2][peak_y - 2]\n",
    "        neg1_2 = data[0][peak_x - 1][peak_y + 2]\n",
    "        neg1_1 = data[0][peak_x - 1][peak_y + 1]\n",
    "        neg1_0 = data[0][peak_x - 1][peak_y]\n",
    "        neg1_neg1 = data[0][peak_x - 1][peak_y - 1]\n",
    "        neg1_neg2 = data[0][peak_x - 1][peak_y - 2]\n",
    "        zero_2 = data[0][peak_x][peak_y + 2]\n",
    "        zero_1 = data[0][peak_x][peak_y + 1]\n",
    "        zero_neg1 = data[0][peak_x][peak_y - 1]\n",
    "        zero_neg2 = data[0][peak_x][peak_y - 2]\n",
    "        pos1_2 = data[0][peak_x + 1][peak_y + 2]\n",
    "        pos1_1 = data[0][peak_x + 1][peak_y + 1]\n",
    "        pos1_0 = data[0][peak_x + 1][peak_y]\n",
    "        pos1_neg1 = data[0][peak_x + 1][peak_y - 1]\n",
    "        pos1_neg2 = data[0][peak_x + 1][peak_y - 2]\n",
    "        pos2_2 = data[0][peak_x + 2][peak_y + 2]\n",
    "        pos2_1 = data[0][peak_x + 2][peak_y + 1]\n",
    "        pos2_0 = data[0][peak_x + 2][peak_y]\n",
    "        pos2_neg1 = data[0][peak_x + 2][peak_y - 1]\n",
    "        pos2_neg2 = data[0][peak_x + 2][peak_y - 2]\n",
    "\n",
    "        z_data = [neg2_2, neg2_1, neg2_0, neg2_neg1, neg2_neg2,\\\n",
    "                neg1_2, neg1_1, neg1_0, neg1_neg1, neg1_neg2,\\\n",
    "                zero_2, zero_1, peak, zero_neg1, zero_neg2,\\\n",
    "                pos1_2, pos1_1, pos1_0, pos1_neg1, pos1_neg2,\\\n",
    "                pos2_2, pos2_1, pos2_0, pos2_neg1, pos2_neg2]\n",
    "        x_data = [-2]*5 + [-1]*5 + [0]*5 + [1]*5 + [2]*5\n",
    "        y_data = [2, 1, 0, -1, -2]*5\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(gaussian_theta, (x_data, y_data), z_data, bounds=([0,0,0,-1,-1],[float('inf'),float('inf'),2*np.pi,1,1]))\n",
    "            amp, sigma, theta, mu_x, mu_y = popt\n",
    "            peak = float(amp)\n",
    "            peak_coord = (float(peak_x + mu_x), float(peak_y + mu_y))\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    elif Gaussian and (not internal) and (peak_x - 1) >= 0 and (peak_x + 1) <= x_dim and (peak_y - 1) >= 0 and (peak_y + 1) <= y_dim:\n",
    "        left_top = data[0][peak_x - 1][peak_y + 1]\n",
    "        left_middle = data[0][peak_x - 1][peak_y]\n",
    "        left_bottom = data[0][peak_x - 1][peak_y - 1]\n",
    "        middle_top = data[0][peak_x][peak_y + 1]\n",
    "        middle_bottom = data[0][peak_x][peak_y - 1]\n",
    "        right_top = data[0][peak_x + 1][peak_y + 1]\n",
    "        right_middle = data[0][peak_x + 1][peak_y]\n",
    "        right_bottom = data[0][peak_x + 1][peak_y - 1]\n",
    "\n",
    "        z_data = [left_top, left_middle, left_bottom, middle_top, peak, middle_bottom, right_top, right_middle, right_bottom]\n",
    "        x_data = [-1]*3 + [0]*3 + [1]*3\n",
    "        y_data = [1, 0, -1] * 3\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(gaussian_theta, (x_data, y_data), z_data, bounds=([0,0,0,-1,-1],[float('inf'),float('inf'),2*np.pi,1,1]))\n",
    "            amp, sigma, theta, mu_x, mu_y = popt\n",
    "            peak = float(amp)\n",
    "            peak_coord = (float(peak_x + mu_x), float(peak_y + mu_y))\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "\n",
    "    rms = float((np.var(masked_data))**0.5)\n",
    "\n",
    "    stats = {'peak': peak, 'field_center': field_center, 'peak_coord': peak_coord, 'rms': rms, 'beam_size': float(beam_size / (u.arcsec**2)),\\\n",
    "              'x_axis': float(x_axis_size / u.arcsec), 'y_axis': float(y_axis_size / u.arcsec), 'incl_area': incl_area}\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incl_excl_data(fits_file: str, center: list = [], radius_buffer: float = 5.0, Gaussian: bool = True, internal: bool = True):\n",
    "    '''\n",
    "    Finds statistics of an inclusion region and its complement, the exclusion region.\n",
    "\n",
    "    The inclusion region can be the union of circles or the complement of such a region.\n",
    "\n",
    "    The statistics are the inclusion region's maximum flux in Jy and its coordinates in pixels,\n",
    "    the exclusion region's maximum flux in Jy and its coordinates in pixels, the exclusion region's rms in Jy,\n",
    "    the number of measurements in the inclusion region, the number of measurements in the exclusion region,\n",
    "    the coordinates in pixels of the image's center, and the radii in pixels of the inclusion zones.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    center : list (optional)\n",
    "        A list of center coordinates in units of pixels.\n",
    "        If no center coordinates are given, eventually defaults to ((length of x-axis)/2, (length of y-axis)/2), rounded up.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with:\n",
    "            float\n",
    "                The inclusion region's maximum flux in Jy.\n",
    "            tuple (int, int)\n",
    "                The coordinates in pixels of the inclusion region's maximum flux.\n",
    "            float\n",
    "                The exclusion region's maximum flux in Jy.\n",
    "            tuple (int, int)\n",
    "                The coordinates in pixels of the exclusion region's maximum flux.\n",
    "            float\n",
    "                The exclusion region's rms in Jy.\n",
    "            float\n",
    "                The number of measurements in the inclusion region.\n",
    "            float\n",
    "                The number of measurements in the exclusion region.\n",
    "            tuple (int, int)\n",
    "                The coordinates in pixels of the image's center.\n",
    "            list\n",
    "                A list with:\n",
    "                    float(s)\n",
    "                        The radii in pixels of inclusion zones.\n",
    "    '''\n",
    "\n",
    "    i = fits_data_index(fits_file)\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    #extract data array\n",
    "    info = file[i]\n",
    "\n",
    "    #get radius, inclusion, exclusion lists for interior and exterior\n",
    "    beam_fwhm = float((info.header['BMAJ'] * (Angle(1, info.header['CUNIT1'])).to(u.arcsec) / u.arcsec)) #in arcsec\n",
    "    radius = [beam_fwhm + radius_buffer]\n",
    "    if len(center) > 1:\n",
    "        radius = radius + ([beam_fwhm] * (len(center) - 1))\n",
    "\n",
    "    #get info on inclusion and exclusion regions\n",
    "    int_info = region_stats(fits_file=fits_file, radius=radius, center=center, Gaussian=Gaussian, internal=internal)\n",
    "    ext_info = region_stats(fits_file=fits_file, radius=radius, center=center, invert=True, Gaussian=False, internal=False)\n",
    "\n",
    "    #getting values for peak, rms, axis lengths, beam size\n",
    "    info_dict = {}\n",
    "    info_dict['int_peak_val'] = int_info['peak']\n",
    "    info_dict['field_center'] = int_info['field_center']\n",
    "    info_dict['int_peak_coord'] = int_info['peak_coord']\n",
    "    info_dict['ext_peak_coord'] = ext_info['peak_coord']\n",
    "    info_dict['ext_peak_val'] = ext_info['peak']\n",
    "    info_dict['rms_val'] = ext_info['rms']\n",
    "    x_axis = int_info['x_axis']\n",
    "    y_axis = int_info['y_axis']\n",
    "    beam_size = int_info['beam_size']\n",
    "\n",
    "    #calculating number of measurements in inclusion and exclusion regions\n",
    "    incl_area = int_info['incl_area']\n",
    "    excl_area = ext_info['incl_area']\n",
    "    info_dict['n_incl_meas'] = incl_area / beam_size\n",
    "    info_dict['n_excl_meas'] = excl_area / beam_size\n",
    "\n",
    "    pix_radius = [] #list of radii in pixels\n",
    "    for r in range(len(radius)):\n",
    "        pix_rad = (Angle(radius[r], u.arcsec).to(info.header['CUNIT1']) / info.header['CDELT1']) / u.Unit(info.header['CUNIT1'])\n",
    "        pix_radius.append(float(pix_rad))\n",
    "    info_dict['radius'] = pix_radius\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_image_rms(fits_file: str, center: list = [], rms: float = None, recursion: bool = True,\\\n",
    "                       radius_buffer: float = 5.0, ext_threshold: float = None, internal: bool = True):\n",
    "    '''\n",
    "    Using the exclusion region's rms taken directly from the image,\n",
    "    finds the probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region,\n",
    "    the probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region, and other statistics.\n",
    "\n",
    "    If the external probability is less than 0.001, updates the inclusion region to include a circle around the external peak.\n",
    "\n",
    "    The other statisitcs are the inclusion region's maximum flux in Jy and its coordinates in pixels,\n",
    "    the exclusion region's maximum flux in Jy and its coordinates in pixels, the exclusion region's rms in Jy,\n",
    "    the number of measurements in the inclusion region, the number of measurements in the exclusion region,\n",
    "    the coordinates in pixels of the image's center, and the radii in pixels of the inclusion zones,\n",
    "    the inclusion region's signal to noise ratio, and the external region's signal to noise ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    center : list (optional)\n",
    "        A list of center coordinates in units of pixels.\n",
    "        If no center coordinates are given, eventually defaults to ((length of x-axis)/2, (length of y-axis)/2), rounded up.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "    rms : float (optional)\n",
    "        An rms value in Jy.\n",
    "        If no value is given, eventually defaults to the rms calculated by incl_excl_data.\n",
    "    recursion : bool (optional)\n",
    "        Whether to use recursion to find significant external peaks, if any.\n",
    "        If no value is given, defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list with:\n",
    "            dict (possibly multiple)\n",
    "                A dictionary with:\n",
    "                    float\n",
    "                        The probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "                    float\n",
    "                        The probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "                    float\n",
    "                        The inclusion region's maximum flux in Jy.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the inclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's maximum flux in Jy.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the exclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's rms in Jy.\n",
    "                    float\n",
    "                        The number of measurements in the inclusion region.\n",
    "                    float\n",
    "                        The number of measurements in the exclusion region.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the image's center.\n",
    "                    list\n",
    "                        A list with:\n",
    "                            float(s)\n",
    "                                The radii in pixels of inclusion zones.\n",
    "                    float\n",
    "                        The inclusion region's signal to noise ratio.\n",
    "                    float\n",
    "                        The exclusion region's signal to noise ratio.\n",
    "    '''\n",
    "    info = incl_excl_data(fits_file, center, radius_buffer, Gaussian=True, internal=internal)\n",
    "    if rms is not None:\n",
    "        info['rms_val'] = rms\n",
    "\n",
    "    #keeping int_peak_val and int_peak coord in the original search area\n",
    "    initial_info = incl_excl_data(fits_file, [], radius_buffer, Gaussian=True, internal=True)\n",
    "    info['int_peak_val'] = initial_info['int_peak_val']\n",
    "    info['int_peak_coord'] = initial_info['int_peak_coord']\n",
    "\n",
    "    int_peak = info['int_peak_val']\n",
    "    ext_peak = info['ext_peak_val']\n",
    "    rms = info['rms_val']\n",
    "    n_incl = info['n_incl_meas']\n",
    "    n_excl = info['n_excl_meas']\n",
    "\n",
    "    #calculate error for rms\n",
    "    rms_err = rms * (n_excl)**(-1/2)\n",
    "\n",
    "    #create normal distributions from rms and error for rms\n",
    "    uncert = np.linspace(-5 * rms_err, 5 * rms_err, 100)\n",
    "    uncert_pdf = norm.pdf(uncert, loc = 0, scale = rms_err)\n",
    "\n",
    "    #sum and normalize to find probabilities\n",
    "    prob_dict = info\n",
    "    prob_dict['int_prob'] = float(sum((norm.cdf((-1 * int_peak)/(rms + uncert)) * n_incl) * uncert_pdf) / sum(uncert_pdf))\n",
    "    prob_dict['ext_prob'] = float(sum((norm.cdf((-1 * ext_peak)/(rms + uncert)) * n_excl) * uncert_pdf) / sum(uncert_pdf))\n",
    "    prob_dict['int_snr'] = float(int_peak / rms)\n",
    "    prob_dict['ext_snr'] = float(ext_peak / rms)\n",
    "\n",
    "    if ext_threshold == None:\n",
    "        if prob_dict['int_snr'] < 20:\n",
    "            ext_threshold = 1e-3\n",
    "        else:\n",
    "            ext_threshold = 1e-6\n",
    "\n",
    "    prob_list = [prob_dict]\n",
    "\n",
    "    if prob_dict['ext_prob'] < ext_threshold and recursion:\n",
    "        if center == []:\n",
    "            new_center = [info['field_center'], info['ext_peak_coord']]\n",
    "        else:\n",
    "            center.append(info['ext_peak_coord'])\n",
    "            new_center = center\n",
    "        new_list = get_prob_image_rms(fits_file, new_center, rms=None, recursion=True, \\\n",
    "                                      radius_buffer=radius_buffer, ext_threshold=ext_threshold, internal=False)\n",
    "        prob_list.extend(new_list)\n",
    "\n",
    "    #using better rms value for calculating probability of peak when just looking in initial area\n",
    "    elif len(prob_list) > 1:\n",
    "        new_list = get_prob_image_rms(fits_file, center=[prob_list[0]['field_center']], rms=prob_list[-1]['rms_val'], \\\n",
    "                                     recursion=False, radius_buffer=radius_buffer, ext_threshold=ext_threshold, internal=True)\n",
    "        new_list.extend(prob_list[1:])\n",
    "        prob_list = new_list\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_rms_est_from_ext(prob_list: list):\n",
    "    '''\n",
    "    Using the rms estimated from the value of the exclusion region's maximum flux,\n",
    "    finds the probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region,\n",
    "    the probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region, and other statistics.\n",
    "\n",
    "    The estimated rms is that the probability of finding such an external peak,\n",
    "    assuming no source in the exclusion region, is 1.\n",
    "    Note: this implies that the external probability will always be 1.\n",
    "\n",
    "    The other statistics include the following as calculated using the rms estimated as described above:\n",
    "    the exclusion region's rms in Jy, the inclusion region's signal to noise ratio,\n",
    "    and the external region's signal to noise ratio.\n",
    "\n",
    "    The remaining statisitcs include the following as calculated using the rms taken directly from the image:\n",
    "    the inclusion region's maximum flux in Jy and its coordinates in pixels,\n",
    "    the exclusion region's maximum flux in Jy and its coordinates in pixels, the exclusion region's rms in Jy,\n",
    "    the number of measurements in the inclusion region, the number of measurements in the exclusion region,\n",
    "    the coordinates in pixels of the image's center, and the radii in pixels of the inclusion zones,\n",
    "    the inclusion region's signal to noise ratio, and the external region's signal to noise ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prob_list : list\n",
    "        The list of statistics, as outputted by get_prob_image_rms(), for an image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list with:\n",
    "            dict(s)\n",
    "                A dictionary with the following, found using the rms taken directly from the image:\n",
    "                    float\n",
    "                        The probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "                    float\n",
    "                        The probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "                    float\n",
    "                        The inclusion region's maximum flux in Jy.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the inclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's maximum flux in Jy.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the exclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's rms in Jy.\n",
    "                    float\n",
    "                        The number of measurements in the inclusion region.\n",
    "                    float\n",
    "                        The number of measurements in the exclusion region.\n",
    "                    tuple (int, int)\n",
    "                        The coordinates in pixels of the image's center.\n",
    "                    list\n",
    "                        A list with:\n",
    "                            float(s)\n",
    "                                The radii in pixels of inclusion zones.\n",
    "                    float\n",
    "                        The inclusion region's signal to noise ratio.\n",
    "                    float\n",
    "                        The exclusion region's signal to noise ratio.\n",
    "            dict\n",
    "                A dictionary with the following, found using the rms estimated as described above:\n",
    "                    float\n",
    "                        The probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "                    float\n",
    "                        The probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "                    float\n",
    "                        The exclusion region's rms in Jy.\n",
    "                    float\n",
    "                        The inclusion region's signal to noise ratio.\n",
    "                    float\n",
    "                        The exclusion region's signal to noise ratio.\n",
    "    '''\n",
    "    info = prob_list[-1]\n",
    "\n",
    "    int_peak_val = info['int_peak_val']\n",
    "    ext_peak_val = info['ext_peak_val']\n",
    "    n_incl_meas = info['n_incl_meas']\n",
    "    n_excl_meas = info['n_excl_meas']\n",
    "\n",
    "    excl_sigma = -1 * norm.ppf(1/n_excl_meas)\n",
    "    rms_val = ext_peak_val / excl_sigma\n",
    "\n",
    "    prob_dict = {}\n",
    "\n",
    "    prob_dict['calc_rms_val'] = float(rms_val)\n",
    "    prob_dict['calc_int_prob'] = float(norm.cdf((-1 * int_peak_val)/(rms_val))) * n_incl_meas\n",
    "    prob_dict['calc_ext_prob'] = float(norm.cdf((-1 * ext_peak_val)/(rms_val))) * n_excl_meas\n",
    "    prob_dict['calc_int_snr'] = float(int_peak_val / rms_val)\n",
    "    prob_dict['calc_ext_snr'] = float(excl_sigma)\n",
    "\n",
    "    prob_list.append(prob_dict)\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(fits_file: str, radius_buffer: float = 5.0, ext_threshold: float = None,\\\n",
    "            short_dict: bool = True, full_list: bool = False, plot: bool = True, save_path: str = ''):\n",
    "    '''\n",
    "    Summarizes an image's statistics into a shorter dictionary, a more detailed dictionary, and/or a plot,\n",
    "    with an option to save the plot as a png.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "    short_dict : bool (optional)\n",
    "        Whether to return the short dictionary of statistics.\n",
    "        If no value is given, defaults to True.\n",
    "    full_list : bool (optional)\n",
    "        Whether to return the more detailed list of statistics.\n",
    "        If no value is given, defaults to False.\n",
    "    plot : bool (optional)\n",
    "        Whether to plot the image and statistics.\n",
    "        If no value is given, defaults to True.\n",
    "    save_path : str (optional)\n",
    "        The path to which the plot will be saved.\n",
    "        If no value is given, defaults to '' and no image is saved.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict (if requested)\n",
    "        A shorter dictionary with:\n",
    "            float\n",
    "                The probability, found using the rms taken directly from the image,\n",
    "                of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "            list\n",
    "                A list with:\n",
    "                    float(s)\n",
    "                        The probabilities, found using the rms taken directly from the image,\n",
    "                        of detecting the exclusion regions' maximum flux if there were no source in the exclusion regions.\n",
    "                        If there are multiple entries in this list,\n",
    "                        they are the probabilities as the exclusion region becomes increasingly small\n",
    "                        as external peaks deemed significant are added to the inclusion region.\n",
    "            float\n",
    "                The inclusion region's maximum flux in Jy.\n",
    "            tuple (float, float)\n",
    "                The coordinates in relative arcsec of the inclusion region's maximum flux.\n",
    "            list\n",
    "                A list of with:\n",
    "                    float(s)\n",
    "                        The exclusion regions' maximum fluxes in Jy.\n",
    "                        If there are multiple entries in this list,\n",
    "                        they are the maxmimum fluxes as the exclusion region becomes increasingly small\n",
    "                        as external peaks deemed significant are added to the inclusion region.\n",
    "            list\n",
    "                A list with:\n",
    "                    tuple(s) (float, float)\n",
    "                        The coordinates in relative arcsec of the exclusion regions' maximum fluxes.\n",
    "                        If there are multiple entires in this list,\n",
    "                        they are the coordinates as the exclusion region becomes increasingly small\n",
    "                        as external peaks deemed significant are added to the inclusion region.\n",
    "            float\n",
    "                The exclusion region's rms in Jy. This uses the final (smallest) exclusion region.\n",
    "            float\n",
    "                The number of measurements in the inclusion region.\n",
    "            float\n",
    "                The number of measurements in the exclusion region.\n",
    "            tuple (int, int)\n",
    "                The coordinates in relative arcsec of the image's center. Should be (0, 0).\n",
    "            list\n",
    "                A list with:\n",
    "                    float(s):\n",
    "                        The radii in arcsec of inclusion zones.\n",
    "            float\n",
    "                The inclusion region's signal to noise ratio.\n",
    "            list\n",
    "                A list with:\n",
    "                    float(s)\n",
    "                        The exclusion regions' signal to noise ratios.\n",
    "            float\n",
    "                The probability, found using the rms estimated from the value of the exclusion region's maximum flux,\n",
    "                of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "            float\n",
    "                The probability, found using the rms estimated from the value of the exclusion region's maximum flux,\n",
    "                of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "            float\n",
    "                The rms in Jy estimated from the value of the exclusion region's maximum flux.\n",
    "            float\n",
    "                The inclusion region's signal to noise ratio,\n",
    "                found using the rms estimated from the value of the exclusion region's maximum flux.\n",
    "            float\n",
    "                The exclusion region's signal to noise ratio,\n",
    "                found using the rms estimated from the value of the exclusion region's maximum flux.\n",
    "    list (if requested)\n",
    "        A more detailed list with:\n",
    "            dict(s)\n",
    "                A dictionary with the following, found using the rms taken directly from the image:\n",
    "                    float\n",
    "                        The probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "                    float\n",
    "                        The probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "                    float\n",
    "                        The inclusion region's maximum flux in Jy.\n",
    "                    tuple (float, float)\n",
    "                        The coordinates in relative arcsec of the inclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's maximum flux in Jy.\n",
    "                    tuple (float, float)\n",
    "                        The coordinates in relative arcsec of the exclusion region's maximum flux.\n",
    "                    float\n",
    "                        The exclusion region's rms in Jy.\n",
    "                    float\n",
    "                        The number of measurements in the inclusion region.\n",
    "                    float\n",
    "                        The number of measurements in the exclusion region.\n",
    "                    tuple (float, float)\n",
    "                        The coordinates in relative arcsec of the image's center. Should be (0.0, 0.0).\n",
    "                    list\n",
    "                        A list with:\n",
    "                            float(s)\n",
    "                                The radii in arcsec of inclusion zones.\n",
    "                    float\n",
    "                        The inclusion region's signal to noise ratio.\n",
    "                    float\n",
    "                        The exclusion region's signal to noise ratio.\n",
    "            dict\n",
    "                A dictionary with the following, found using the rms estimated as described above:\n",
    "                    float\n",
    "                        The probability of detecting the inclusion region's maximum flux if there were no source in the inclusion region.\n",
    "                    float\n",
    "                        The probability of detecting the exclusion region's maximum flux if there were no source in the exclusion region.\n",
    "                    float\n",
    "                        The exclusion region's rms in Jy.\n",
    "                    float\n",
    "                        The inclusion region's signal to noise ratio.\n",
    "                    float\n",
    "                        The exclusion region's signal to noise ratio.\n",
    "    '''\n",
    "    m_info = get_prob_image_rms(fits_file, radius_buffer=radius_buffer, ext_threshold=ext_threshold, internal=True)\n",
    "\n",
    "    info = (get_prob_rms_est_from_ext(m_info.copy()))\n",
    "\n",
    "    center = m_info[0]['field_center']\n",
    "\n",
    "    header_data = fits.getheader(fits_file)\n",
    "    pixel_scale = Angle(header_data['CDELT1'], header_data['CUNIT1']).to_value('arcsec')\n",
    "\n",
    "    int_x_coord = np.array([m_info[0]['int_peak_coord'][0]])\n",
    "    int_y_coord = np.array([m_info[0]['int_peak_coord'][1]])\n",
    "\n",
    "    #normalize internal peak coordinates\n",
    "    int_x_coord = (int_x_coord - center[0]) * pixel_scale\n",
    "    int_y_coord = (int_y_coord - center[1]) * pixel_scale\n",
    "\n",
    "    int_radius = m_info[0]['radius'][0] #in pixels\n",
    "\n",
    "    if len(m_info) > 1:\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "\n",
    "        for i in range(len(m_info)-1):\n",
    "            #normalized external peak coordinates\n",
    "            x_coords.append((m_info[i]['ext_peak_coord'][0] - center[0]) * pixel_scale)\n",
    "            y_coords.append((m_info[i]['ext_peak_coord'][1] - center[1]) * pixel_scale)\n",
    "        ext_radius = m_info[-1]['radius'][1]\n",
    "\n",
    "        x_coords = np.array(x_coords)\n",
    "        y_coords = np.array(y_coords)\n",
    "\n",
    "    if plot:\n",
    "        #plt.rcParams['font.family'] = 'serif'\n",
    "        #plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "        plt.rcParams['font.size'] = 15\n",
    "        plt.rcParams['hatch.linewidth'] = 0.5\n",
    "        plt.rcParams['figure.dpi'] = 60\n",
    "\n",
    "        image_data = fits.getdata(fits_file)\n",
    "        shape = image_data.shape\n",
    "\n",
    "        while len(shape) > 2:\n",
    "            image_data = image_data[0]\n",
    "            shape = image_data.shape\n",
    "\n",
    "        plt.set_cmap('inferno')\n",
    "        fig, ax = plt.subplots(figsize=(6.7,5.1))\n",
    "\n",
    "        plt.plot(int_x_coord, int_y_coord, 'wo', fillstyle='none', markersize=15)\n",
    "        plt.plot(int_x_coord, int_y_coord, 'kx', fillstyle='none', markersize=15/np.sqrt(2))\n",
    "\n",
    "        int_circle = patches.Circle((0, 0), int_radius * pixel_scale, edgecolor='c', fill=False)\n",
    "        ax.add_artist(int_circle)\n",
    "\n",
    "        if len(m_info) > 1:\n",
    "            plt.plot(x_coords, y_coords, 'ko', fillstyle='none', markersize=15)\n",
    "            plt.plot(x_coords, y_coords, 'wx', fillstyle='none', markersize=15/np.sqrt(2))\n",
    "\n",
    "            for i in range(len(x_coords)):\n",
    "                ext_circle = patches.Circle((x_coords[i], y_coords[i]), ext_radius * pixel_scale, edgecolor='lime', fill=False)\n",
    "                ax.add_artist(ext_circle)\n",
    "        int_snr = m_info[-1]['int_snr']\n",
    "\n",
    "        x_min = ((0 - center[0]) - 0.5) * pixel_scale\n",
    "        y_min = ((0 - center[1]) - 0.5) * pixel_scale\n",
    "        x_max = ((image_data.shape[0] -  center[0]) - 0.5) * pixel_scale\n",
    "        y_max = ((image_data.shape[1] -  center[1]) - 0.5) * pixel_scale\n",
    "\n",
    "        beam = patches.Ellipse((x_min*0.88, y_min*0.92), Angle(header_data['BMIN'], header_data['CUNIT1']).to_value('arcsec'),\\\n",
    "                               Angle(header_data['BMAJ'], header_data['CUNIT1']).to_value('arcsec'), fill=True, facecolor='w',\\\n",
    "                                edgecolor='k', angle=header_data['BPA'], hatch='/////', lw=1)\n",
    "        ax.add_artist(beam)\n",
    "\n",
    "        title = fits_file[fits_file.rindex('/')+1:fits_file.index('.fits')]\n",
    "        ax.text(x_min*0.96, y_max*0.96, f'Source: {title}\\nInternal Candidate SNR: {int_snr:.2f}', horizontalalignment='left', verticalalignment='top',\\\n",
    "                fontsize=10, bbox=dict(facecolor='w'))\n",
    "\n",
    "        plt.imshow(image_data, extent=[x_min, x_max, y_min, y_max], origin='lower')\n",
    "\n",
    "        plt.xlabel('Relative RA Offset [arcsec]', fontsize=15)\n",
    "        plt.ylabel('Relative Dec Offset [arcsec]', fontsize=15)\n",
    "\n",
    "        jy_to_mjy = lambda x, pos: '{}'.format(round(x*1000, 1))\n",
    "        fmt = ticker.FuncFormatter(jy_to_mjy)\n",
    "\n",
    "        cbar = plt.colorbar(shrink=0.8, format=fmt)\n",
    "        cbar.ax.set_ylabel('Intensity [mJy/beam]', fontsize=15, rotation=270, labelpad=24)\n",
    "\n",
    "        if save_path != '':\n",
    "            try:\n",
    "                file = fits_file\n",
    "                while '/' in file:\n",
    "                    file = file[file.index('/')+1:]\n",
    "                file = file.replace('.fits', '')\n",
    "                if ext_threshold == None:\n",
    "                    ext_threshold = 'default'\n",
    "                file += f'_rb{radius_buffer}_et{ext_threshold}'\n",
    "                if save_path[-1] != '/':\n",
    "                    save_path = save_path + '/'\n",
    "                plt.savefig(f'{save_path}{file}.jpg')\n",
    "            except:\n",
    "                print('Error saving figure. Double check path entered.')\n",
    "\n",
    "    ext_peaks = 'No significant external peak'\n",
    "    ext_vals = 'No significant external peak'\n",
    "    ext_snrs = 'No significant external peak'\n",
    "    ext_probs = 'No significant external peak'\n",
    "\n",
    "    if len(m_info) > 1:\n",
    "        ext_peaks = []\n",
    "        ext_vals = []\n",
    "        ext_snrs = []\n",
    "        ext_probs = []\n",
    "    for i in range(len(m_info)-1):\n",
    "        ext_peaks.append((float(x_coords[i]), float(y_coords[i])))\n",
    "        ext_vals.append(m_info[i]['ext_peak_val'])\n",
    "        ext_snrs.append(m_info[i]['ext_snr'])\n",
    "        ext_probs.append(m_info[i]['ext_prob'])\n",
    "\n",
    "    #convert radii from pixels to arcsec\n",
    "    new_rad = []\n",
    "    for j in range(len(m_info[-1]['radius'])):\n",
    "        new_rad.append(float(m_info[-1]['radius'][j] * pixel_scale))\n",
    "\n",
    "    short_info = {'int_peak_val': m_info[-1]['int_peak_val'], 'int_peak_coord': (float(int_x_coord[0]), float(int_y_coord[0])), 'int_snr': m_info[-1]['int_snr'],\\\n",
    "                  'calc_int_snr': info[-1]['calc_int_snr'], 'int_prob': m_info[-1]['int_prob'], 'calc_int_prob': info[-1]['calc_int_prob'],\\\n",
    "                  'ext_peak_val': ext_vals, 'ext_peak_coord': ext_peaks, 'ext_snr': ext_snrs,\\\n",
    "                  'calc_ext_snr': info[-1]['calc_ext_snr'], 'ext_prob': ext_probs, 'calc_ext_prob': info[-1]['calc_ext_prob'],\\\n",
    "                  'field_center': (0,0), 'rms': m_info[-1]['rms_val'], 'calc_rms_val': info[-1]['calc_rms_val'],\\\n",
    "                  'n_incl_meas': m_info[-1]['n_incl_meas'], 'n_excl_meas': m_info[-1]['n_excl_meas'], 'radius': new_rad}\n",
    "\n",
    "    #normalizing coordinates in the full list\n",
    "    if full_list:\n",
    "        for d in info:\n",
    "            for key, value in d.items():\n",
    "                #convert coordinates from pixels to relative arcsec\n",
    "                if type(value) == tuple:\n",
    "                    new_coords = (float((value[0] - center[0]) * pixel_scale), float((value[1] - center[1]) * pixel_scale))\n",
    "                    d[key] = new_coords\n",
    "\n",
    "                #convert radii from pixels to arcsec\n",
    "                new_radius = []\n",
    "                if key == 'radius':\n",
    "                    for k in range(len(value)):\n",
    "                        new_radius.append(float(value[k] * pixel_scale))\n",
    "                    d[key] = new_radius\n",
    "\n",
    "    center = (0,0) #normalizing center coordinates\n",
    "\n",
    "    if short_dict and full_list:\n",
    "        return short_info, info\n",
    "\n",
    "    elif full_list:\n",
    "        return info\n",
    "\n",
    "    elif short_dict:\n",
    "        return short_info\n",
    "\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant(fits_file: str, threshold: float = 0.01, radius_buffer: float = 5.0, ext_threshold: float = None):\n",
    "    '''\n",
    "    Finds whether a significant source was detected in a field's center region.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    threshold : float (optional)\n",
    "        The threshold for a significant detection.\n",
    "        If the probability of detecting the center region's maximum flux assuming no source in the image\n",
    "        is less than this threshold, then the detection is deemed significant.\n",
    "        If no value is given, defaults to 0.01.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool : Whether a significant source was detected in the field's center region.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If threshold is not between 0 and 1, inclusive.\n",
    "    '''\n",
    "\n",
    "    #make sure reasonable input\n",
    "    if not (threshold >= 0 and threshold <= 1):\n",
    "        raise ValueError('Threshold must be between 0 and 1, inclusive.')\n",
    "\n",
    "    summ = summary(fits_file, radius_buffer=radius_buffer, ext_threshold=ext_threshold, short_dict=True, full_list=False, plot=False)\n",
    "    return (summ['int_prob'] < threshold and summ['calc_int_prob'] < threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catalog(fits_file: str, threshold: float = 0.01, radius_buffer: float = 5.0, ext_threshold: float = None):\n",
    "    '''\n",
    "    Summarizes information on any significant point sources detected in an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    threshold : float (optional)\n",
    "        The threshold for a significant detection.\n",
    "        If the probability of detecting the center region's maximum flux assuming no source in the image\n",
    "        is less than this threshold, then the detection is deemed significant.\n",
    "        If no value is given, defaults to 0.01.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with:\n",
    "            dict(s)\n",
    "                A dictionary with:\n",
    "                    str\n",
    "                        The name of the target object of the observation.\n",
    "                    str\n",
    "                        The date and time of the observation.\n",
    "                    str\n",
    "                        The name of the FITS file with the image.\n",
    "                    Angle\n",
    "                        The restoring beam major axis.\n",
    "                    Angle\n",
    "                        The restoring beam minor axis.\n",
    "                    Angle\n",
    "                        The restoring beam position angle.\n",
    "                    float\n",
    "                        The uncertainty in flux density measurements. The rms excluding any significant sources and a small circular region around them.\n",
    "                    float\n",
    "                        The flux density of the detected point source.\n",
    "                    SkyCoord\n",
    "                        The location of the detected point source.\n",
    "                    bool\n",
    "                        Whether the detected point source is in the initial search region.\n",
    "    '''\n",
    "\n",
    "    summ = summary(fits_file, radius_buffer=radius_buffer, ext_threshold=ext_threshold, short_dict=True, full_list=False, plot=False)\n",
    "\n",
    "    header_data = fits.getheader(fits_file)\n",
    "    name = header_data['OBJECT']\n",
    "    obs_date_time = header_data['DATE-OBS']\n",
    "    bmaj = header_data['BMAJ']\n",
    "    bmin = header_data['BMIN']\n",
    "    bpa = header_data['BPA']\n",
    "    ctype1 = header_data['CTYPE1']\n",
    "    crval1 = header_data['CRVAL1']\n",
    "    cunit1 = header_data['CUNIT1']\n",
    "    ctype2 = header_data['CTYPE2']\n",
    "    crval2 = header_data['CRVAL2']\n",
    "    cunit2 = header_data['CUNIT2']\n",
    "    ctype3 = header_data['CTYPE3']\n",
    "    crval3 = header_data['CRVAL3']\n",
    "    cunit3 = header_data['CUNIT3']\n",
    "\n",
    "    freq = 'Not found'\n",
    "    if ctype3 == 'FREQ':\n",
    "        freq = str(crval3) + cunit3\n",
    "\n",
    "    #assume beam axes in same units as CUNIT1 and CUNIT2 and BPA in degrees\n",
    "    beam_maj_axis = Angle(bmaj, cunit1)\n",
    "    beam_min_axis = Angle(bmin, cunit1)\n",
    "    beam_pos_angle = Angle(bpa, u.degree)\n",
    "    bpa_rad = beam_pos_angle.to(u.rad) / u.rad\n",
    "\n",
    "    interesting_sources = {}\n",
    "    field_info = {'Field Name': name, 'Obs Date Time': obs_date_time, 'File Name': fits_file[fits_file.rindex('/')+1:],\\\n",
    "                    'Beam Maj Axis': round(float(beam_maj_axis.to(u.arcsec)/u.arcsec), 3) * u.arcsec,\\\n",
    "                    'Beam Min Axis': round(float(beam_min_axis.to(u.arcsec)/u.arcsec), 3) * u.arcsec,\\\n",
    "                    'Beam Pos Angle': round(float(beam_pos_angle.to(u.deg)/u.deg), 3) * u.deg,\\\n",
    "                    'Freq': freq, 'Flux Uncert': round(summ['rms'] * 1000, 3) * u.mJy,}\n",
    "\n",
    "    n_ext_sources = 0\n",
    "    if type(summ['ext_peak_val']) == list:\n",
    "        n_ext_sources += len(summ['ext_peak_val'])\n",
    "\n",
    "    ra_index = 0\n",
    "    dec_index = 1\n",
    "\n",
    "    if 'RA' in ctype1:\n",
    "        ra = crval1\n",
    "    elif 'RA' in ctype2:\n",
    "        ra = crval2\n",
    "        ra_index = 1\n",
    "    else:\n",
    "        raise ValueError('No RA in image')\n",
    "\n",
    "    if 'DEC' in ctype1:\n",
    "        dec = crval1\n",
    "        dec_index = 0\n",
    "    elif 'DEC' in ctype2:\n",
    "        dec = crval2\n",
    "    else:\n",
    "        raise ValueError('No dec in image')\n",
    "\n",
    "    if cunit1 != cunit2:\n",
    "        raise ValueError('Axes have different units')\n",
    "\n",
    "    center = SkyCoord(ra, dec, unit=cunit1)\n",
    "\n",
    "    pt_source_count = 1\n",
    "\n",
    "    if significant(fits_file, threshold=threshold, radius_buffer=radius_buffer, ext_threshold=ext_threshold):\n",
    "        int_info = field_info.copy()\n",
    "        int_info['Flux Density'] = round(summ['int_peak_val'] * 1000, 3) * u.mJy\n",
    "\n",
    "        snr = summ['int_snr']\n",
    "        b_min_uncert = float(beam_maj_axis.to(u.arcsec)/u.arcsec / snr)\n",
    "        b_maj_uncert = float(beam_min_axis.to(u.arcsec)/u.arcsec / snr)\n",
    "        int_info['RA Uncert'] = round(b_min_uncert*abs(math.sin(bpa_rad)) + b_maj_uncert*abs(math.cos(bpa_rad)), 3) * u.arcsec\n",
    "        int_info['Dec Uncert'] = round(b_maj_uncert*abs(math.sin(bpa_rad)) + b_min_uncert*abs(math.cos(bpa_rad)), 3) * u.arcsec\n",
    "\n",
    "        int_ra_offset = summ['int_peak_coord'][ra_index] * u.arcsec\n",
    "        int_dec_offset = summ['int_peak_coord'][dec_index] * u.arcsec\n",
    "        coord = center.spherical_offsets_by(int_ra_offset, int_dec_offset)\n",
    "\n",
    "        ra_str = str(coord.ra)\n",
    "        dec_str = str(coord.dec)\n",
    "\n",
    "        try:\n",
    "            m_index = ra_str.index('m')\n",
    "            s_index = ra_str.index('s')\n",
    "            ra_seconds = ra_str[m_index + 1: s_index]\n",
    "            ra_str = ra_str[:m_index + 1] + str(round(float(ra_seconds), 2)) + 's'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            m_index = dec_str.index('m')\n",
    "            s_index = dec_str.index('s')\n",
    "            dec_seconds = dec_str[m_index + 1: s_index]\n",
    "            dec_str = dec_str[:m_index + 1] + str(round(float(dec_seconds), 2)) + 's'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        int_info['Coord RA'] = ra_str\n",
    "        int_info['Coord Dec'] = dec_str\n",
    "        int_info['Internal'] = True\n",
    "\n",
    "        key = f'Source {pt_source_count}'\n",
    "        interesting_sources[key] = int_info\n",
    "        pt_source_count +=1\n",
    "\n",
    "    for i in range(n_ext_sources):\n",
    "        ext_info = field_info.copy()\n",
    "        ext_info['Flux Density'] = round(summ['ext_peak_val'][i] * 1000, 3) * u.mJy\n",
    "\n",
    "        snr = summ['ext_snr'][i]\n",
    "        b_min_uncert = float(beam_maj_axis.to(u.arcsec)/u.arcsec / snr)\n",
    "        b_maj_uncert = float(beam_min_axis.to(u.arcsec)/u.arcsec / snr)\n",
    "        ext_info['RA Uncert'] = round(b_min_uncert*abs(math.sin(bpa_rad)) + b_maj_uncert*abs(math.cos(bpa_rad)), 3) * u.arcsec\n",
    "        ext_info['Dec Uncert'] = round(b_maj_uncert*abs(math.sin(bpa_rad)) + b_min_uncert*abs(math.cos(bpa_rad)), 3) * u.arcsec\n",
    "\n",
    "        ext_ra_offset = summ['ext_peak_coord'][i][ra_index] * u.arcsec\n",
    "        ext_dec_offset = summ['ext_peak_coord'][i][dec_index] * u.arcsec\n",
    "        coord = center.spherical_offsets_by(ext_ra_offset, ext_dec_offset)\n",
    "\n",
    "        ra_str = str(coord.ra)\n",
    "        dec_str = str(coord.dec)\n",
    "\n",
    "        try:\n",
    "            m_index = ra_str.index('m')\n",
    "            s_index = ra_str.index('s')\n",
    "            ra_seconds = ra_str[m_index + 1: s_index]\n",
    "            ra_str = ra_str[:m_index + 1] + str(round(float(ra_seconds), 2)) + 's'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            m_index = dec_str.index('m')\n",
    "            s_index = dec_str.index('s')\n",
    "            dec_seconds = dec_str[m_index + 1: s_index]\n",
    "            dec_str = dec_str[:m_index + 1] + str(round(float(dec_seconds), 2)) + 's'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ext_info['Coord RA'] = ra_str\n",
    "        ext_info['Coord Dec'] = dec_str\n",
    "        ext_info['Internal'] = False\n",
    "\n",
    "        key = f'Source {pt_source_count}'\n",
    "        interesting_sources[key] = ext_info\n",
    "        pt_source_count += 1\n",
    "\n",
    "    if 'Source 1' not in interesting_sources:\n",
    "        return\n",
    "    else:\n",
    "        return interesting_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_catalogs(catalog_1: dict, catalog_2: dict):\n",
    "    '''\n",
    "    Combines two catalogs in the format returned by make_catalog() into a single catalog of the same format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog_1 : dict\n",
    "        The catalog to which the other catalog will be \"appended.\"\n",
    "    catalog_2 : dict\n",
    "        The catalog to \"append\" to the other catalog.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary of the combined catalogs in the same catalog format.\n",
    "    '''\n",
    "\n",
    "    shift = len(catalog_1)\n",
    "    for key, value in catalog_2.items():\n",
    "        new_number = int(key.replace('Source ', ''))\n",
    "        new_key = f'Source {new_number + shift}'\n",
    "        catalog_1[new_key] = value\n",
    "    return catalog_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_html(html_path):\n",
    "    '''\n",
    "    Starts source_info.html, in which source information can be stored.\n",
    "    '''\n",
    "\n",
    "    with open(html_path, 'w') as html_file:\n",
    "        start = '''\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <style>\n",
    "        img.field {\n",
    "        width: 40%;\n",
    "        height: 40%\n",
    "        }\n",
    "        img.bp {\n",
    "        width: 20%;\n",
    "        height: 20%\n",
    "        }\n",
    "        img.gain {\n",
    "        width: 45%;\n",
    "        height: 45%\n",
    "        }\n",
    "        .centered-large-text {\n",
    "        text-align: center;\n",
    "        font-size: 36px;\n",
    "        }\n",
    "        </style>\n",
    "        <body>\n",
    "        '''\n",
    "        html_file.write(start)\n",
    "        html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_info_to_html(json_file: str, html_path: str):\n",
    "    '''\n",
    "    Appends observation information table to source_info.html using information from a .json file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_file : str\n",
    "        The path of the .json file that contains the observation information.\n",
    "    '''\n",
    "\n",
    "    with open(html_path, 'a') as html_file:\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                obs_dict = json.load(file)\n",
    "\n",
    "            #cleaning up obs_dict\n",
    "            for key, value in obs_dict.items():\n",
    "                if type(value) == list:\n",
    "                    string = ', '.join(value)\n",
    "                    obs_dict[key] = [string]\n",
    "            obs_id = obs_dict.pop('obsID')\n",
    "            base_name = obs_dict.pop('basename')\n",
    "\n",
    "            df = pd.DataFrame(obs_dict)\n",
    "            df_transposed = df.T\n",
    "\n",
    "            html_table = df_transposed.to_html()\n",
    "\n",
    "            html_file.write(f'<p class=\\'centered-large-text\\'>Source Information for {base_name} (ObsID {obs_id}) </p>')\n",
    "            html_file.write(html_table)\n",
    "        except:\n",
    "            html_file.write('<p> Error generating observation information table. </p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_eff_to_html(html_path, matlab: str):\n",
    "\n",
    "    try:\n",
    "        data = loadmat(matlab)\n",
    "        ap_eff_array = data['apEffCorr']\n",
    "\n",
    "        n_ants = len(ap_eff_array)\n",
    "        panda_dict = {}\n",
    "\n",
    "        for ant in range(n_ants):\n",
    "            ant_eff = {}\n",
    "            ant_eff['RxA LSB'] = float(ap_eff_array[ant][0])\n",
    "            ant_eff['RxA USB'] = float(ap_eff_array[ant][1])\n",
    "            ant_eff['RxB LSB'] = float(ap_eff_array[ant][2])\n",
    "            ant_eff['RxB USB'] = float(ap_eff_array[ant][3])\n",
    "            panda_dict[f'Ant {ant+1}'] = ant_eff\n",
    "\n",
    "        df = pd.DataFrame.from_dict(panda_dict)\n",
    "        df_transposed = df.T\n",
    "        html_table = df_transposed.to_html()\n",
    "\n",
    "        with open(html_path, 'a') as html_file:\n",
    "            html_file.write(html_table)\n",
    "    except:\n",
    "        print('Error with aperture efficiency data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plots(html_path, matlab: str):\n",
    "\n",
    "    plt.rcdefaults()\n",
    "    plt.rcParams['figure.dpi'] = 60\n",
    "    plt.rcParams['font.size'] = 8\n",
    "\n",
    "\n",
    "    data = loadmat(matlab)\n",
    "    gt = data['gainTime']\n",
    "    gws = data['gainWinSoln']\n",
    "    gcs = data['gainChanSoln']\n",
    "    gain_type = data['gainType']\n",
    "\n",
    "    n_times = len(gt)\n",
    "    n_ants = len(gws[0])\n",
    "    n_spws = len(gws[0][0])\n",
    "    n_chans = len(gcs[0][0][0])\n",
    "\n",
    "    utc_midpts = []\n",
    "    for t in range(len(gt)):\n",
    "        midpt = 0.5 * (gt[t][0].real + gt[t][0].imag)\n",
    "        utc_midpts.append((midpt%1)*24)\n",
    "\n",
    "    colors = ['blue','r','y','purple','orange','g','m','c']\n",
    "\n",
    "    chan_bit = 7\n",
    "    if all(bit == 0 for bit in (gain_type & (2**chan_bit))):\n",
    "        chan_bit = 0\n",
    "    spw_bit = 6\n",
    "    if all(bit == 0 for bit in (gain_type & (2**spw_bit))):\n",
    "        spw_bit = 1\n",
    "\n",
    "    #plotting bandpass gain solutions for amplitude and phase\n",
    "    fig, ax = plt.subplots(nrows=n_ants, ncols=1, sharex=True, figsize=(3,8))\n",
    "    fig2, ax2 = plt.subplots(nrows=n_ants, ncols=1, sharex=True, figsize=(3,8))\n",
    "\n",
    "    max_amp = 0\n",
    "\n",
    "    for time in range(n_times):\n",
    "        if (gain_type & (2**chan_bit))[time] != 0:\n",
    "            for ant in range(n_ants):\n",
    "\n",
    "                #shifting for cosmetics\n",
    "                pos = ax[ant].get_position()\n",
    "                pos.x0 += 0.05\n",
    "                pos.x1 += 0.05\n",
    "                ax[ant].set_position(pos)\n",
    "                pos2 = ax2[ant].get_position()\n",
    "                pos2.x0 += 0.06\n",
    "                pos2.x1 += 0.06\n",
    "                ax2[ant].set_position(pos2)\n",
    "\n",
    "                #no x axis ticks\n",
    "                ax[ant].xaxis.set_tick_params(labelbottom=False)\n",
    "                ax2[ant].xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "\n",
    "                for spw in range(n_spws):\n",
    "                    amp_to_plot = [abs(a) for a in gcs.copy()[time][ant][spw]]\n",
    "                    pha_to_plot = [np.angle(p, deg=True) for p in gcs.copy()[time][ant][spw]]\n",
    "                    if max(amp_to_plot) > max_amp:\n",
    "                        max_amp = max(amp_to_plot)\n",
    "\n",
    "                    x_axis = np.arange(spw * n_chans + 1, (1 + spw) * n_chans + 1)\n",
    "\n",
    "                    ax[ant].scatter(x_axis, amp_to_plot, c=colors[spw], s=20, marker='x', linewidths=1.5)\n",
    "                    ax2[ant].scatter(x_axis, pha_to_plot, c=colors[spw], s=20, marker='x', linewidths=1.5)\n",
    "\n",
    "                    ax[ant].yaxis.set_label_position('right')\n",
    "                    ax2[ant].yaxis.set_label_position('right')\n",
    "                    ax[ant].set_ylabel(f'Ant{ant+1}')\n",
    "                    ax2[ant].set_ylabel(f'Ant{ant+1}')\n",
    "\n",
    "    plt.setp(ax, yticks=np.arange(0, max_amp+1, 0.5))\n",
    "    plt.setp(ax2, yticks=[-180,-120,-60,0,60,120,180])\n",
    "    fig.suptitle('Bandpass gain solutions for amplitude', y=0.92)\n",
    "    fig2.suptitle('Bandpass gain solutions for phase', y=0.92)\n",
    "    fig.supxlabel('Full antenna bandwidth', y=0.07)\n",
    "    fig2.supxlabel('Full antenna bandwidth', y=0.07)\n",
    "    fig.supylabel('Gain amplitude')\n",
    "    fig2.supylabel('Gain phase')\n",
    "\n",
    "    html_folder = os.path.dirname(html_path)\n",
    "\n",
    "    fig.savefig(os.path.join(html_folder, 'bp_amp.jpg'))\n",
    "    fig2.savefig(os.path.join(html_folder, 'bp_pha.jpg'))\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    #plotting gain solutions for amplitude and phase\n",
    "    n_rows = math.ceil(n_ants / 2)\n",
    "    n_cols = 2\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, sharex=True, figsize=(5.7,4))\n",
    "    fig2, ax2 = plt.subplots(nrows=n_rows, ncols=n_cols, sharex=True, figsize=(5.7,4))\n",
    "\n",
    "    max_amp, min_time, max_time = 0, float('inf'), 0\n",
    "\n",
    "    for spw in range(n_spws):\n",
    "        for ant in range(n_ants):\n",
    "            amp_to_plot, pha_to_plot = [], []\n",
    "            times = []\n",
    "\n",
    "            if ant < n_rows:\n",
    "                row, col = ant, 0\n",
    "\n",
    "                #shifting for cosmetics\n",
    "                pos = ax[row, col].get_position()\n",
    "                pos.x0 -= 0.005\n",
    "                pos.x1 -= 0.005\n",
    "                ax[row, col].set_position(pos)\n",
    "                pos2 = ax2[row, col].get_position()\n",
    "                pos2.x0 -= 0.005\n",
    "                pos2.x1 -= 0.005\n",
    "                ax2[row, col].set_position(pos2)\n",
    "            else:\n",
    "                row, col = ant % n_rows, 1\n",
    "\n",
    "            for time in range(n_times):\n",
    "                if gain_type[time] & (2**6) != 0:\n",
    "                    amp_val = abs((gws.copy())[time][ant][spw])\n",
    "                    pha_val = np.angle((gws.copy())[time][ant][spw], deg=True)\n",
    "                    amp_to_plot.append(amp_val)\n",
    "                    pha_to_plot.append(pha_val)\n",
    "\n",
    "                    if amp_val > max_amp:\n",
    "                        max_amp = amp_val\n",
    "\n",
    "                    t = utc_midpts[time]\n",
    "                    if t < min_time:\n",
    "                        min_time = t\n",
    "                    if t > max_time:\n",
    "                        max_time = t\n",
    "\n",
    "                    times.append(t)\n",
    "\n",
    "            ax[row, col].scatter(times, amp_to_plot, c=colors[spw], s=4, marker='D')\n",
    "            ax2[row, col].scatter(times, pha_to_plot, c=colors[spw], s=4, marker='D')\n",
    "\n",
    "            ax[row, col].yaxis.set_label_position('right')\n",
    "            ax2[row, col].yaxis.set_label_position('right')\n",
    "            ax[row, col].set_ylabel(f'Ant{ant+1}')\n",
    "            ax2[row, col].set_ylabel(f'Ant{ant+1}')\n",
    "            amp_to_plot, pha_to_plot = [], []\n",
    "\n",
    "    plt.setp(ax, xticks=np.arange(min_time//1, math.ceil(max_time), 1), yticks=np.arange(0, max_amp+1, 0.5))\n",
    "    plt.setp(ax2, xticks=np.arange(min_time//1, math.ceil(max_time), 1), yticks=[-180,-120,-60,0,60,120,180])\n",
    "    fig.suptitle('Gain solutions for amplitude')\n",
    "    fig2.suptitle('Gain solutions for phase')\n",
    "    fig.supxlabel('UT hours')\n",
    "    fig2.supxlabel('UT hours')\n",
    "    fig.supylabel('Gain amplitude')\n",
    "    fig2.supylabel('Gain phase')\n",
    "\n",
    "    fig.savefig(os.path.join(html_folder, 'g_amp.jpg'))\n",
    "    fig2.savefig(os.path.join(html_folder, 'g_pha.jpg'))\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_to_html(html_path: str, fits_file: str, radius_buffer: float = 5.0, ext_threshold: float = None):\n",
    "    '''\n",
    "    Appends source figures to source_info.html.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        The path of the FITS file that contains the image.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "    '''\n",
    "\n",
    "    with open(html_path, 'a') as html_file:\n",
    "        try:\n",
    "            summary(fits_file=fits_file, radius_buffer=radius_buffer, ext_threshold=ext_threshold,\\\n",
    "                    short_dict=False, full_list=False, plot=True, save_path=os.path.dirname(html_path))\n",
    "\n",
    "            #getting full path\n",
    "            file = fits_file\n",
    "            while '/' in file:\n",
    "                file = file[file.index('/')+1:]\n",
    "            file = file.replace('.fits', '')\n",
    "            if ext_threshold == None:\n",
    "                ext_threshold = 'default'\n",
    "            file += f'_rb{radius_buffer}_et{ext_threshold}'\n",
    "            full_path = f'./{file}.jpg'\n",
    "\n",
    "            html_figure = f'''\n",
    "            <img class=\\'field\\' src=\\'{full_path}\\'>\n",
    "            <br>\n",
    "            '''\n",
    "\n",
    "            html_file.write(html_figure)\n",
    "        except:\n",
    "            html_file.write(f'<p> Error generating figure for {fits_file}. </p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalog_to_html(catalog: dict, html_path):\n",
    "    '''\n",
    "    Appends source information table to source_info.html.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    catalog : dict\n",
    "        A catalog in the format returned by make_catalog().\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame.from_dict(catalog)\n",
    "    df_transposed = df.T\n",
    "    html_table = df_transposed.to_html()\n",
    "\n",
    "    with open(html_path, 'a') as html_file:\n",
    "        html_file.write(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_html(html_path: str):\n",
    "    '''\n",
    "    Ends source_info.html, in which source information can be stored.\n",
    "    '''\n",
    "\n",
    "    with open(html_path, 'a') as html_file:\n",
    "\n",
    "        end = '''\n",
    "        </body>\n",
    "        </html>\n",
    "        '''\n",
    "\n",
    "        html_file.write(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_html_and_txt(folder: str, threshold: float = 0.01, radius_buffer: float = 5.0, ext_threshold: float = None):\n",
    "    '''\n",
    "    From a folder of FITS files, creates source_info.html with observation information table, source figures, and source information table\n",
    "    and creates interesting_field.txt with names of objects with any (possibly) interesting detections.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str\n",
    "        The path of the folder containing the FITS files to be analyzed.\n",
    "    threshold : float (optional)\n",
    "        The threshold for a significant detection.\n",
    "        If the probability of detecting the center region's maximum flux assuming no source in the image\n",
    "        is less than this threshold, then the detection is deemed significant.\n",
    "        If no value is given, defaults to 0.01.\n",
    "    radius_buffer : float (optional)\n",
    "        The amount of buffer, in arcsec, to add to the beam FWHM to get the initial search radius.\n",
    "        If no value is given, defaults to 5 arcsec.\n",
    "    ext_threshold : float (optional)\n",
    "        The probability that an external peak must be below for it to be considered an external source.\n",
    "        If no value is given, defaults to 0.001.\n",
    "    '''\n",
    "\n",
    "    html_path = os.path.join(folder, 'index.html')\n",
    "    matlab_file = os.path.join(folder, 'gains.mat')\n",
    "\n",
    "    start_html(html_path)\n",
    "\n",
    "    json_file = os.path.join(folder, 'polaris.json')\n",
    "\n",
    "    obs_info_to_html(json_file, html_path)\n",
    "\n",
    "    ap_eff_to_html(html_path, matlab_file)\n",
    "\n",
    "    try:\n",
    "        calibration_plots(html_path, matlab_file)\n",
    "\n",
    "        with open(html_path, 'a') as html_file:\n",
    "            html_gain_info = f'''\n",
    "            <img class=\\'bp\\' src=\\'./bp_amp.jpg'\\'>\n",
    "            <img class=\\'bp\\' src=\\'./bp_pha.jpg'\\'>\n",
    "            <br>\n",
    "            <img class=\\'gain\\' src=\\'./g_amp.jpg'\\'>\n",
    "            <img class=\\'gain\\' src=\\'./g_pha.jpg'\\'>\n",
    "            <br>\n",
    "            '''\n",
    "            html_file.write(html_gain_info)\n",
    "    except:\n",
    "        print('Error with gain calibration information.')\n",
    "\n",
    "    final_catalog = {}\n",
    "    with open(json_file, 'r') as file:\n",
    "        obs_dict = json.load(file)\n",
    "\n",
    "    sci_targs = [targ.lower() for targ in obs_dict[ 'sciTargs']]\n",
    "    pol_cals = [cal.lower() for cal in obs_dict['polCals']]\n",
    "    with open(os.path.join(folder, 'interesting_fields.txt'), 'w') as txt:\n",
    "        for file in glob.glob(os.path.join(folder, '*.fits')):\n",
    "            obj = fits.getheader(file)['OBJECT']\n",
    "            if obj.lower() not in pol_cals:\n",
    "                fig_to_html(html_path, file, radius_buffer=radius_buffer, ext_threshold=ext_threshold)\n",
    "            if obj.lower() in sci_targs:\n",
    "                catalog = make_catalog(file, threshold=threshold, radius_buffer=radius_buffer, ext_threshold=ext_threshold)\n",
    "\n",
    "                #add field name to .txt file if it is a science target with a significant detection in the initial inclusion region\n",
    "                if catalog != None:\n",
    "                    for key, value in catalog.items():\n",
    "                        if value['Internal'] == True:\n",
    "                            txt.write(f'{obj}\\n')\n",
    "                    final_catalog = combine_catalogs(final_catalog, catalog)\n",
    "\n",
    "    catalog_to_html(final_catalog, html_path)\n",
    "    end_html(html_path)\n",
    "\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(summary('../data/250611_03:56:34/1310+323_lr_full.fits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "full_html_and_txt('../data/250611_03:56:34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f full_html_and_txt full_html_and_txt('../data/250611_03:56:34/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_catalog('/reduction/karto/SMA/polaris_test/250103_05:25:18/g232.6207+00.9959_full.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
