{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from astropy.coordinates import Angle\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_data_index(fits_file: str):\n",
    "    '''Given a FITS file, return the index of the file where the data array is'''\n",
    "\n",
    "    file_index = 0\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    info = file[file_index]\n",
    "    data = info.data\n",
    "    while data is None:\n",
    "        #going through the indices of file to find the array\n",
    "        try:\n",
    "            file_index += 1\n",
    "            info = file[file_index]\n",
    "            data = info.data\n",
    "        except:\n",
    "            print(f'Error in locating data index of {fits_file}')\n",
    "\n",
    "    return file_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_stats(fits_file: str, center: list = [], radius: list = [], invert: bool = False):\n",
    "    '''Given a FITS file, list of center coordinates in units of pixels,\n",
    "    list of radii in units of arcsec (include measurements within this radius of the center),\n",
    "    and Boolean of whether to invert (if True, becomes exclude instead of include),\n",
    "    return a dictionary with floats of the maximum flux (in Jy), coordinates of field center (in pixels),\n",
    "    coordinates of maximum flux (in pixels), rms (in Jy), beam size (in arcsec^2),\n",
    "    x axis length (in arcsec), and y axis length (in arcsec) in the specified region.\n",
    "    If no center given, will eventually default to center of ((length of x-axis)/2, (length of y-axis)/2), rounded up.\n",
    "    '''\n",
    "\n",
    "    if center != [] and len(center) != len(radius):\n",
    "        raise IndexError ('Center list and radius list lengths do not match')\n",
    "\n",
    "    i = fits_data_index(fits_file)\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    #extract data array\n",
    "    info = file[i]\n",
    "    data = info.data\n",
    "\n",
    "    #getting dimensions for array\n",
    "    try:\n",
    "        dims = data.shape\n",
    "        x_dim = dims[1]\n",
    "        y_dim = dims[2]\n",
    "    except:\n",
    "        print('Data dimension error')\n",
    "\n",
    "    x_dist_array = np.tile(np.arange(x_dim),(y_dim, 1)) #array of each pixel's horizontal distance (in pixels) from y-axis\n",
    "    y_dist_array = x_dist_array.T #array of each pixel's vertical distance (in pixels) from x-axis\n",
    "\n",
    "    #keep center pixel coordinates if specified, set to default if unspecified\n",
    "    center_pix = center\n",
    "    field_center = (round(x_dim/2), round(y_dim/2))\n",
    "    if center == []:\n",
    "        center_pix = [field_center]\n",
    "        if len(radius) > 1:\n",
    "            center_pix = center_pix * len(radius)\n",
    "\n",
    "    #find units of axes\n",
    "    x_unit = info.header['CUNIT1']\n",
    "    y_unit = info.header['CUNIT2']\n",
    "\n",
    "    #find cell size (units of arcsec)\n",
    "    x_cell_size = (Angle(info.header['CDELT1'], x_unit)).to(u.arcsec)\n",
    "    y_cell_size = (Angle(info.header['CDELT2'], y_unit)).to(u.arcsec)\n",
    "\n",
    "    #find major axis (units of arcsec), minor axis (units of arcsec), beam size (units of arcsec^2)\n",
    "    beam_size = ((np.pi/4) * info.header['BMAJ'] * info.header['BMIN'] * Angle(1, x_unit) * Angle(1, y_unit) / np.log(2)).to(u.arcsec**2)\n",
    "\n",
    "    #find axis sizes\n",
    "    x_axis_size = info.header['NAXIS1'] * x_cell_size\n",
    "    y_axis_size = info.header['NAXIS2'] * y_cell_size\n",
    "\n",
    "    #distance from center array\n",
    "    dist_from_center =((((x_dist_array - center_pix[0][0])*x_cell_size)**2 + ((y_dist_array - center_pix[0][1])*y_cell_size)**2)**0.5)\n",
    "\n",
    "    #boolean mask and apply\n",
    "    mask = (dist_from_center <= radius[0] * u.arcsec)\n",
    "    if len(center) > 1:\n",
    "        for j in range(1, len(center)):\n",
    "            dist_from_center = ((((x_dist_array - center_pix[j][0])*x_cell_size)**2 + ((y_dist_array - center_pix[j][1])*y_cell_size)**2)**0.5)\n",
    "            mask = np.logical_or(mask, (dist_from_center <= radius[j] * u.arcsec))\n",
    "\n",
    "    if invert:\n",
    "        mask = np.logical_not(mask)\n",
    "\n",
    "    masked_data = data[0][mask]\n",
    "\n",
    "    #get peak, rms, beam_size values\n",
    "    try:\n",
    "        peak = float(max(masked_data))\n",
    "    except ValueError:\n",
    "        print('No values after mask applied. Check inclusion and exclusion radii.')\n",
    "\n",
    "    #find coordinates of peak\n",
    "    peak_pix = np.where(data[0] == peak)\n",
    "    x = peak_pix[1][0]\n",
    "    y = peak_pix[0][0]\n",
    "    peak_coord = (int(x_dist_array[0][x]), int(y_dist_array[y][0]))\n",
    "\n",
    "    rms = float((np.var(masked_data))**0.5)\n",
    "\n",
    "    stats = {'peak': peak, 'field_center': field_center, 'peak_coord': peak_coord, 'rms': rms, 'beam_size': float(beam_size / (u.arcsec**2)),\\\n",
    "              'x_axis': float(x_axis_size / u.arcsec), 'y_axis': float(y_axis_size / u.arcsec)}\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incl_excl_data(fits_file: str, center: list = []):\n",
    "    '''Given a FITS file and (optional) list of tuples of center coordinates in units of arcsec,\n",
    "    return a dictionary with the field center coordinates as tuple, peak flux value of the inclusion area, coordinates of this peak as tuple,\n",
    "    peak flux value of the exclusion area, coordinates of this peak as tuple, rms value of the exclusion area,\n",
    "    number of measurements in the inclusion area, and number of measurements in the exclusion area of the specified circle.\n",
    "    '''\n",
    "\n",
    "    i = fits_data_index(fits_file)\n",
    "\n",
    "    #open FITS file\n",
    "    try:\n",
    "        file = fits.open(fits_file)\n",
    "    except:\n",
    "        print(f'Unable to open {fits_file}')\n",
    "\n",
    "    #extract data array\n",
    "    info = file[i]\n",
    "\n",
    "    #get radius, inclusion, exclusion lists for interior and exterior\n",
    "    radius = [float((info.header['BMAJ'] * (Angle(1, info.header['CUNIT1'])).to(u.arcsec) / u.arcsec) + 5)] #major axis + 5 arcsec\n",
    "    if len(center) > 1:\n",
    "        radius = radius + ([radius[0] - 5.0] * (len(center) - 1))\n",
    "\n",
    "    #get info on inclusion and exclusion regions\n",
    "    int_info = region_stats(fits_file = fits_file, radius = radius, center = center)\n",
    "    ext_info = region_stats(fits_file = fits_file, radius = radius, center = center, invert=True)\n",
    "\n",
    "    #getting values for peak, rms, axis lengths, beam size, distance list\n",
    "    info_dict = {}\n",
    "    info_dict['int_peak_val'] = int_info['peak']\n",
    "    info_dict['field_center'] = int_info['field_center']\n",
    "    info_dict['int_peak_coord'] = int_info['peak_coord']\n",
    "    info_dict['ext_peak_coord'] = ext_info['peak_coord']\n",
    "    info_dict['ext_peak_val'] = ext_info['peak']\n",
    "    info_dict['rms_val'] = ext_info['rms']\n",
    "    x_axis = int_info['x_axis']\n",
    "    y_axis = int_info['y_axis']\n",
    "    beam_size = int_info['beam_size']\n",
    "\n",
    "    #calculating number of measurements in inclusion and exclusion regions\n",
    "    incl_area = np.pi * ((radius[0]**2) + ((radius[0] - 5.0)**2) * (len(center)- 1))\n",
    "    excl_area = x_axis * y_axis - incl_area\n",
    "    info_dict['n_incl_meas'] = incl_area / beam_size\n",
    "    info_dict['n_excl_meas'] = excl_area / beam_size\n",
    "\n",
    "    pix_radius = [] #list of radii in pixels\n",
    "    for r in range(len(radius)):\n",
    "        pix_rad = (Angle(radius[r], u.arcsec).to(info.header['CUNIT1']) / info.header['CDELT1']) / info.header['CUNIT1']\n",
    "        pix_radius.append(float(pix_rad))\n",
    "    info_dict['radius'] = pix_radius\n",
    "\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_rms_prob(fits_file: str, center: list = [], rms: float = None, reps: bool = False, recursion: bool = True):\n",
    "    '''Given a FITS file, (optional) list of tuples of center coordinates in units of arcsec,\n",
    "    (optional) rms value, and (optional) choice to use recursion, return a list of dictionaries.\n",
    "    The first dictionary contains the probability of the peak to noise ratio of the interior of the specified region\n",
    "    and the probability of peak to noise ratio of the exterior of the specified region,\n",
    "    with noise being the measured rms in the exclusion area.\n",
    "    If the external probability is less than 0.001, there will be subsequent dictionaries\n",
    "    that contain the probability of the peak to noise ratio of the interior of the specified region\n",
    "    and the probability of peak to noise ratio of the exterior of the specified region,\n",
    "    with noise being the measured rms in the exclusion area,\n",
    "    but the included region is expanded to include the highest excluded peak of the previous excluded region\n",
    "    and the excluded region now excludes that highest peak.\n",
    "    '''\n",
    "    info = incl_excl_data(fits_file, center)\n",
    "    if rms is not None:\n",
    "        info['rms_val'] = rms\n",
    "\n",
    "    if reps: #keeping int_peak_val and int_peak coord in the original search area\n",
    "        initial_info = incl_excl_data(fits_file, [center[0]])\n",
    "        info['int_peak_val'] = initial_info['int_peak_val']\n",
    "        info['int_peak_coord'] = initial_info['int_peak_coord']\n",
    "\n",
    "    int_peak = info['int_peak_val']\n",
    "    ext_peak = info['ext_peak_val']\n",
    "    rms = info['rms_val']\n",
    "    n_incl = info['n_incl_meas']\n",
    "    n_excl = info['n_excl_meas']\n",
    "\n",
    "    #calculate error for rms\n",
    "    rms_err = rms * (n_excl)**(-1/2)\n",
    "\n",
    "    #create normal distributions from rms and error for rms\n",
    "    uncert = np.linspace(-5 * rms_err, 5 * rms_err, 100)\n",
    "    uncert_pdf = norm.pdf(uncert, loc = 0, scale = rms_err)\n",
    "\n",
    "    #sum and normalize to find probabilities\n",
    "    prob_dict = info\n",
    "    prob_dict['int_prob'] = float(sum((norm.cdf((-1 * int_peak)/(rms + uncert)) * n_incl) * uncert_pdf) / sum(uncert_pdf))\n",
    "    prob_dict['ext_prob'] = float(sum((norm.cdf((-1 * ext_peak)/(rms + uncert)) * n_excl) * uncert_pdf) / sum(uncert_pdf))\n",
    "    prob_dict['int_snr'] = float(int_peak / rms)\n",
    "    prob_dict['ext_snr'] = float(ext_peak / rms)\n",
    "\n",
    "    prob_list = [prob_dict]\n",
    "\n",
    "    if prob_dict['ext_prob'] < 0.001 and recursion:\n",
    "        reps = True\n",
    "        if center == []:\n",
    "            new_center = [info['field_center'], info['ext_peak_coord']]\n",
    "        else:\n",
    "            center.append(info['ext_peak_coord'])\n",
    "            new_center = center\n",
    "        new_list = meas_rms_prob(fits_file, new_center, rms = None, reps = reps, recursion = True)\n",
    "        prob_list.extend(new_list)\n",
    "\n",
    "    #using better rms value for calculating probability of peak when just looking in initial area\n",
    "    elif len(prob_list) > 1:\n",
    "        new_list = meas_rms_prob(fits_file, center = [prob_list[0]['field_center']], rms = prob_list[-1]['rms_val'], \\\n",
    "                                     reps = False, recursion = False)\n",
    "        new_list.extend(prob_list[1:])\n",
    "        prob_list = new_list\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rms_prob(prob_list: list):\n",
    "    '''Given a list output from meas_rms_prob(), return the list output with an appended dictionary\n",
    "    that contains the probability of the peak to noise ratio of the interior of the specified region\n",
    "    and the probability of peak to noise ratio of the exterior of the specified region,\n",
    "    calculated rms, calculated interior peak to noise ratio, and calculated exterior peak to noise ratio\n",
    "    with noise being the calculated rms in the exclusion area based on the expected probability of the peak value in the exclusion area.\n",
    "    '''\n",
    "    info = prob_list[-1]\n",
    "\n",
    "    int_peak_val = info['int_peak_val']\n",
    "    ext_peak_val = info['ext_peak_val']\n",
    "    n_incl_meas = info['n_incl_meas']\n",
    "    n_excl_meas = info['n_excl_meas']\n",
    "\n",
    "    excl_sigma = -1 * norm.ppf(1/n_excl_meas)\n",
    "    rms_val = ext_peak_val / excl_sigma\n",
    "\n",
    "    prob_dict= {}\n",
    "\n",
    "    prob_dict['calc_rms_val'] = float(rms_val)\n",
    "    prob_dict['calc_int_prob'] = float(norm.cdf((-1 * int_peak_val)/(rms_val))) * n_incl_meas\n",
    "    prob_dict['calc_ext_prob'] = float(norm.cdf((-1 * ext_peak_val)/(rms_val))) * n_excl_meas\n",
    "    prob_dict['calc_int_snr'] = float(int_peak_val / rms_val)\n",
    "    prob_dict['calc_ext_snr'] = float(excl_sigma)\n",
    "\n",
    "    prob_list.append(prob_dict)\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(fits_file: str, short_dict: bool = True, full_dict: bool = False, plot: bool = True, save_path: str = ''):\n",
    "    '''Given a FITS file, (optional) choice to return a list of information, (optional) choice to show a plot,\n",
    "    and (optional) path of where to save a png of the plot,\n",
    "    return a list of source information if requested and a plot of source information if requested\n",
    "    and save a png of the plot to the path if requested.\n",
    "    '''\n",
    "    m_info = meas_rms_prob(fits_file)\n",
    "\n",
    "    info = (calc_rms_prob(meas_rms_prob(fits_file)))\n",
    "\n",
    "    center = m_info[0]['field_center']\n",
    "\n",
    "    int_x_coord = np.array([m_info[0]['int_peak_coord'][0]])\n",
    "    int_y_coord = np.array([m_info[0]['int_peak_coord'][1]])\n",
    "\n",
    "    int_radius = m_info[0]['radius'][0]\n",
    "\n",
    "    if len(m_info) > 1:\n",
    "        x_coords = []\n",
    "        y_coords = []\n",
    "\n",
    "        for i in range(len(m_info)-1):\n",
    "            x_coords.append(m_info[i]['ext_peak_coord'][0])\n",
    "            y_coords.append(m_info[i]['ext_peak_coord'][1])\n",
    "        ext_radius = m_info[-1]['radius'][1]\n",
    "\n",
    "        x_coords = np.array(x_coords)\n",
    "        y_coords = np.array(y_coords)\n",
    "\n",
    "    if plot:\n",
    "        header_data = fits.getheader(fits_file)\n",
    "        pixel_scale = Angle(header_data['CDELT1'], header_data['CUNIT1']).to_value('arcsec')\n",
    "        image_data = fits.getdata(fits_file)\n",
    "        shape = image_data.shape\n",
    "\n",
    "        if len(shape) > 2:\n",
    "            image_data = image_data[0]\n",
    "\n",
    "        plt.set_cmap('jet')\n",
    "        fig, ax = plt.subplots(figsize=(7,7))\n",
    "        int_x_coord = (int_x_coord - center[0]) * pixel_scale\n",
    "        int_y_coord = (int_y_coord - center[1]) * pixel_scale\n",
    "\n",
    "        plt.plot(int_x_coord, int_y_coord, 'wo', fillstyle='none', markersize=15)\n",
    "        plt.plot(int_x_coord, int_y_coord, 'kx', fillstyle='none', markersize=15/np.sqrt(2))\n",
    "\n",
    "        int_circle = patches.Circle((0, 0), int_radius * pixel_scale, edgecolor='r', fill=False)\n",
    "        ax.add_artist(int_circle)\n",
    "\n",
    "        if len(m_info) > 1:\n",
    "            x_coords = (x_coords - center[0]) * pixel_scale\n",
    "            y_coords = (y_coords - center[1]) * pixel_scale\n",
    "            plt.plot(x_coords, y_coords, 'ko', fillstyle='none', markersize=15)\n",
    "            plt.plot(x_coords, y_coords, 'wx', fillstyle='none', markersize=15/np.sqrt(2))\n",
    "\n",
    "            for i in range(len(x_coords)):\n",
    "                ext_circle = patches.Circle((x_coords[i], y_coords[i]), ext_radius * pixel_scale, edgecolor='hotpink', fill=False)\n",
    "                ax.add_artist(ext_circle)\n",
    "        int_snr = m_info[-1]['int_snr']\n",
    "\n",
    "        x_min = ((0 - center[0]) - 0.5) * pixel_scale\n",
    "        y_min = ((0 - center[1]) - 0.5) * pixel_scale\n",
    "        x_max = ((image_data.shape[0] -  center[0]) - 0.5) * pixel_scale\n",
    "        y_max = ((image_data.shape[1] -  center[1]) - 0.5) * pixel_scale\n",
    "\n",
    "        ax.text(x_min*0.9, y_max*0.9, f'Internal Candidate SNR:\\n{int_snr}', fontsize=8, horizontalalignment='left', verticalalignment='top', bbox=dict(facecolor='w'))\n",
    "\n",
    "        plt.imshow(image_data, extent=[x_min, x_max, y_min, y_max], origin='lower')\n",
    "        plt.title(fits_file)\n",
    "        plt.colorbar(shrink=0.4)\n",
    "\n",
    "        if save_path != '':\n",
    "            try:\n",
    "                file = fits_file\n",
    "                while '/' in file:\n",
    "                    file = file[file.index('/')+1:]\n",
    "                file = file.replace('.fits', '')\n",
    "                if save_path[-1] != '/':\n",
    "                    save_path = save_path + '/'\n",
    "                plt.savefig(f'{save_path}{file}.png')\n",
    "            except:\n",
    "                print('Error saving figure. Double check path entered.')\n",
    "\n",
    "\n",
    "    ext_peaks = 'No significant external peak'\n",
    "    ext_vals = 'No significant external peak'\n",
    "    ext_snrs = 'No significant external peak'\n",
    "    ext_probs = 'No significant external peak'\n",
    "\n",
    "    for i in range(len(m_info)-1):\n",
    "        ext_peaks = []\n",
    "        ext_vals = []\n",
    "        ext_snrs = []\n",
    "        ext_probs = []\n",
    "        ext_peaks.append(m_info[i]['ext_peak_coord'])\n",
    "        ext_vals.append(m_info[i]['ext_peak_val'])\n",
    "        ext_snrs.append(m_info[i]['ext_snr'])\n",
    "        ext_probs.append(m_info[i]['ext_prob'])\n",
    "\n",
    "    short_info = {'int_peak_val': m_info[-1]['int_peak_val'], 'int_peak_coord': (int(int_x_coord[0]), int(int_y_coord[0])), 'int_snr': m_info[-1]['int_snr'],\\\n",
    "                  'calc_int_snr': info[-1]['calc_int_snr'], 'int_prob': m_info[-1]['int_prob'], 'calc_int_prob': info[-1]['calc_int_prob'],\\\n",
    "                  'ext_peak_val': ext_vals, 'ext_peak_coord': ext_peaks, 'ext_snr': ext_snrs,\\\n",
    "                  'calc_ext_snr': info[-1]['calc_ext_snr'], 'ext_prob': ext_probs, 'calc_ext_prob': info[-1]['calc_ext_prob'],\\\n",
    "                  'field_center': center, 'rms': m_info[-1]['rms_val'], 'calc_rms_val': info[-1]['calc_rms_val'],\\\n",
    "                  'n_incl_meas': m_info[-1]['n_incl_meas'], 'n_excl_meas': m_info[-1]['n_excl_meas'], 'radius': m_info[-1]['radius']}\n",
    "\n",
    "    if short_dict and full_dict:\n",
    "        return info, short_info\n",
    "\n",
    "    elif full_dict:\n",
    "        return info\n",
    "\n",
    "    elif short_dict:\n",
    "        return short_info\n",
    "\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant(fits_file: str, threshold: float = 0.05):\n",
    "    '''Given a fits file and (optional) threshold probability,\n",
    "    return a Boolean of whether a significant detection occurred.\n",
    "    Significant detection entails both the internal probability based on the measured rms\n",
    "    and the internal probability based on the calculated rms\n",
    "    being less than the threshold probability'''\n",
    "\n",
    "    #make sure reasonable input\n",
    "    if not (threshold >= 0 or threshold <= 1):\n",
    "        raise Exception('Threshold must be between 0 and 1, inclusive.')\n",
    "\n",
    "    summ = summary(fits_file, True, False, False)\n",
    "    return (summ['int_prob'] < threshold and summ['calc_int_prob'] < threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in glob.glob('../data/11151/*.fits'):\n",
    "    #try:\n",
    "        #summary(file, False, False, True, '../data/11151/figs_11151/')\n",
    "    #except Exception:\n",
    "        #print('Try again for %s' % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in glob.glob('../data/*.fits'):\n",
    "    #try:\n",
    "        #summary(file, False, False, True, '../data/figs_misc')\n",
    "    #except Exception:\n",
    "        #print('Try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in glob.glob('../data/multi_track/*.fits'):\n",
    "    #try:\n",
    "        #summary(file, False, False, True, '../data/multi_track/figs_multi_track')\n",
    "    #except Exception:\n",
    "        #print('Try again')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
