{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bcfdf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from find_source import make_catalog, combine_catalogs\n",
    "import pandas as pd\n",
    "import os\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c3f4c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_level_csv(folder, csv_path = './low_level.csv'):\n",
    "\n",
    "    master_catalog = None\n",
    "    old_df = None\n",
    "    obs_id = 'Not Found'\n",
    "\n",
    "    try:\n",
    "        old_df = pd.read_csv(csv_path)\n",
    "        master_catalog = (old_df.T).to_dict()\n",
    "        mode = 'a'\n",
    "        header = False\n",
    "    except pd.errors.EmptyDataError: #if the file has no header and no data\n",
    "        mode = 'w'\n",
    "        header = True\n",
    "    except FileNotFoundError: #file not found\n",
    "        mode = 'w'\n",
    "        header = True\n",
    "\n",
    "    try:\n",
    "        json_file = os.path.join(folder, 'polaris.json')\n",
    "        with open(json_file, 'r') as file:\n",
    "            obs_dict = json.load(file)\n",
    "\n",
    "            #cleaning up obs_dict\n",
    "            for key, value in obs_dict.items():\n",
    "                if type(value) == list:\n",
    "                    string = ', '.join(value)\n",
    "                    obs_dict[key] = [string]\n",
    "            obs_id = obs_dict.pop('obsID')\n",
    "        if old_df is not None:\n",
    "            old_df = old_df[old_df['Obs ID'] != obs_id] #removing old or outdated entries\n",
    "    except Exception as e:\n",
    "        print(f'Error with obsID: {e}. WARNING: Old/outdated data may not be deleted.')\n",
    "\n",
    "    for file in glob.glob(os.path.join(folder, '*.fits')):\n",
    "        try:\n",
    "            catalog = make_catalog(file)\n",
    "            for value in catalog.values():\n",
    "                value['Obs ID'] = obs_id\n",
    "                value['Source ID'] = None\n",
    "            if master_catalog is None:\n",
    "                master_catalog = catalog\n",
    "            elif catalog is not None:\n",
    "                master_catalog = combine_catalogs(master_catalog, catalog)\n",
    "        except Exception as e:\n",
    "            print(f'Error for {file}: {e}')\n",
    "\n",
    "    df = pd.DataFrame.from_dict(master_catalog)\n",
    "    df = df.T\n",
    "    df.to_csv(csv_path, mode=mode, header=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fd24b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_source(df, index1, index2):\n",
    "\n",
    "    coord1 = SkyCoord(df['Coord RA'].iloc[index1], df['Coord Dec'].iloc[index1])\n",
    "    coord2 = SkyCoord(df['Coord RA'].iloc[index2], df['Coord Dec'].iloc[index2])\n",
    "    sep = coord1.separation(coord2)\n",
    "    fwhm1 = float(df['Beam Maj Axis'].iloc[index1].replace(' arcsec', ''))\n",
    "    fwhm2 = float(df['Beam Maj Axis'].iloc[index2].replace(' arcsec', ''))\n",
    "    max_sep = (fwhm1 * fwhm2)**(1/2) * u.arcsec\n",
    "    if sep <= max_sep:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50515cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_level_csv(low_level_path = './low_level.csv', high_level_path = './high_level.csv'):\n",
    "\n",
    "    low_df = pd.read_csv(low_level_path)\n",
    "    fields = low_df['Field Name']\n",
    "    n_rows = len(fields)\n",
    "    unique_fields = {}\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        name = (fields[i]).lower() #lower to prevent issues with case sensitivity\n",
    "        if name not in unique_fields:\n",
    "            unique_fields[name] = [i]\n",
    "        else:\n",
    "            unique_fields[name].append(i)\n",
    "\n",
    "    try:\n",
    "        high_df = pd.read_csv(high_level_path)\n",
    "        source_catalog = (high_df.T).to_dict(orient='list')\n",
    "        for key in source_catalog.keys():\n",
    "            if type(key) != str:\n",
    "                del source_catalog[key]\n",
    "    except Exception:\n",
    "        source_catalog = {}\n",
    "\n",
    "    for key, value in unique_fields.items():\n",
    "        for i in value:\n",
    "            source_count = 1\n",
    "            source_name = f'{key}_{source_count}'\n",
    "            added = False\n",
    "            while (source_name in source_catalog) and (not added):\n",
    "                for j in source_catalog[source_name]:\n",
    "                    if i == j:\n",
    "                        added = True\n",
    "                        break\n",
    "                    elif same_source(df=low_df, index1=i, index2=j):\n",
    "                        source_catalog[source_name].append(i)\n",
    "                        added = True\n",
    "                        break\n",
    "                source_count += 1\n",
    "                source_name = f'{key}_{source_count}'\n",
    "            if not added:\n",
    "                source_catalog[source_name] = [i]\n",
    "\n",
    "    max_length = max(len(row_list) for row_list in source_catalog.values())\n",
    "    for row_list in source_catalog.values():\n",
    "        row_list += [None] * (max_length - len(row_list))\n",
    "\n",
    "    new_high_df = pd.DataFrame.from_dict(source_catalog)\n",
    "    new_high_df = new_high_df.T\n",
    "    new_high_df.to_csv(high_level_path, mode='w', header=False, index=True, index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0ca8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc54a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ../data/250611_03:56:34/1743-038_full.fits: \"Keyword 'BMAJ' not found.\"\n",
      "CPU times: user 7.85 s, sys: 246 ms, total: 8.09 s\n",
      "Wall time: 8.78 s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#low_level_csv('../data/250611_03:56:34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ef1cf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f make_catalog low_level_csv('../data/multi_track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "650d3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f low_level_csv low_level_csv('../data/multi_track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c91ae561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f high_level_csv high_level_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
